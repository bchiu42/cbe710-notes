

<!DOCTYPE html>


<html >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Monte Carlo and Intro to Molecular Dynamics Simulations &#8212; Notes for CBE710</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/defs.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'lecture_files/Lecture11';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="MD Thermostats" href="Lecture12.html" />
    <link rel="prev" title="Monte Carlo Simulations" href="Lecture10.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="None"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    <p class="title logo__title">Notes for CBE710</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Class introduction
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Statistical Mechanics</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Lecture1A.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="Lecture1B.html">Review of thermodynamics</a></li>
<li class="toctree-l1"><a class="reference internal" href="Lecture2.html">The Microcanonical Ensemble</a></li>
<li class="toctree-l1"><a class="reference internal" href="Lecture3.html">The Canonical Ensemble</a></li>
<li class="toctree-l1"><a class="reference internal" href="../problems/ps_1/problem_set_1.html">— Problem Set 1 —</a></li>
<li class="toctree-l1"><a class="reference internal" href="Lecture4.html">Canonical Ensemble Continued</a></li>
<li class="toctree-l1"><a class="reference internal" href="Lecture5.html">Generalized Ensembles</a></li>
<li class="toctree-l1"><a class="reference internal" href="Lecture6.html">The Ideal Gas Partition Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="Lecture7.html">The Langmuir Isotherm and Ising Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="Lecture8.html">The Ising Model and Mean-Field Theory</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Molecular Simulation</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Lecture9.html">Fluctuations and an Introduction to Molecular Simulation</a></li>
<li class="toctree-l1"><a class="reference internal" href="Lecture10.html">Monte Carlo Simulations</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Monte Carlo and Intro to Molecular Dynamics Simulations</a></li>
<li class="toctree-l1"><a class="reference internal" href="Lecture12.html">MD Thermostats</a></li>
<li class="toctree-l1"><a class="reference internal" href="Lecture13.html">The Structure of Classical Fluids</a></li>
<li class="toctree-l1"><a class="reference internal" href="Lecture14.html">The Potential of Mean Force</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Thermodynamics</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Lecture15.html">Free energy perturbation</a></li>
<li class="toctree-l1"><a class="reference internal" href="Lecture16.html">Postulates of thermodynamics</a></li>
<li class="toctree-l1"><a class="reference internal" href="Lecture17.html">Heat Engines and Possible Processes</a></li>
<li class="toctree-l1"><a class="reference internal" href="Lecture18.html">Entropy</a></li>
<li class="toctree-l1"><a class="reference internal" href="Lecture19.html">The Fundamental Relation of Thermodynamics</a></li>
<li class="toctree-l1"><a class="reference internal" href="Lecture20.html">Legendre Transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="Lecture21.html">Conditions of equilibrium</a></li>
<li class="toctree-l1"><a class="reference internal" href="Lecture22.html">Equilibrium in single-component systems</a></li>
<li class="toctree-l1"><a class="reference internal" href="Lecture23.html">Phase Diagrams</a></li>
<li class="toctree-l1"><a class="reference internal" href="Lecture24.html">Fugacity</a></li>
<li class="toctree-l1"><a class="reference internal" href="Lecture25.html">Ideal mixtures</a></li>
<li class="toctree-l1"><a class="reference internal" href="Lecture26.html">Non-ideal mixtures</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/lecture_files/Lecture11.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Monte Carlo and Intro to Molecular Dynamics Simulations</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#recommended-textbooks">Recommended textbooks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#topics-in-this-lecture">Topics in this lecture</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#announcements">Announcements</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#importance-sampling-and-markov-chains">Importance sampling and Markov chains</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#detailed-balance-and-the-metropolis-algorithm">Detailed balance and the Metropolis algorithm</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#molecular-dynamics-the-idea">Molecular dynamics: the idea</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#calculating-forces">Calculating forces</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="monte-carlo-and-intro-to-molecular-dynamics-simulations">
<h1>Monte Carlo and Intro to Molecular Dynamics Simulations<a class="headerlink" href="#monte-carlo-and-intro-to-molecular-dynamics-simulations" title="Permalink to this headline">#</a></h1>
<section id="recommended-textbooks">
<h2>Recommended textbooks<a class="headerlink" href="#recommended-textbooks" title="Permalink to this headline">#</a></h2>
<p>Frenkel and Smit Chapter 4.</p>
</section>
<section id="topics-in-this-lecture">
<h2>Topics in this lecture<a class="headerlink" href="#topics-in-this-lecture" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Metropolis Monte Carlo</p></li>
<li><p>Molecular Dynamics</p></li>
</ul>
</section>
<section id="announcements">
<h2>Announcements<a class="headerlink" href="#announcements" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Exam 1 today, 6-7:30 PM, EH 3024</p></li>
<li><p>Sim. project to be assigned today/tomorrow</p></li>
</ul>
</section>
<section id="importance-sampling-and-markov-chains">
<h2>Importance sampling and Markov chains<a class="headerlink" href="#importance-sampling-and-markov-chains" title="Permalink to this headline">#</a></h2>
<p>In the last lecture, we began to introduce the idea of the Metropolis
Monte Carlo method for sampling the canonical ensemble. Briefly, our
goal is to develop an algorithm that stochastically samples system
configurations that occur with a high probability and thus contribute
meaningfully to the system partition function. By doing so, we can
compute ensemble-average quantities using the equation:</p>
<div class="math notranslate nohighlight">
\[\begin{aligned}
\langle Y \rangle_{NVT} &amp;= \int d \mathbf{r}^N p(\textbf{r}^N)_{NVT}  Y(\mathbf{r}^N) 
\end{aligned}\]</div>
<p>The challenge is only sampling states that have a large value of
<span class="math notranslate nohighlight">\(p(\textbf{r}^N)_{NVT}\)</span>. However, if we sample states from the actual
canonical probability distribution itself, then we could approximate the
value of <span class="math notranslate nohighlight">\(\langle Y \rangle\)</span> as a simple average over the number of
states sampled (or number of trials). At no point do we actually need to
calculate the partition function itself, which would be effectively
impossible.</p>
<p>Our problem then boils down to: how do we select states according to the
correct probability distribution without knowing the value of the
partition function? To do so, we will generate a <strong>Markov chain of
states</strong> as a means of sampling our distribution. A Markov chain refers
to a <em>sequence</em> of states (i.e. configurations or trials using our
previous nomenclature) that satisfy the following two conditions:</p>
<ul class="simple">
<li><p>Each state generated belongs to a finite set of possible outcomes
called the state space. The statistical mechanical analogue to this
statement is to say that each microstate generated belongs to a
finite ensemble. We can denote each possible state by
<span class="math notranslate nohighlight">\(\mathbf{r}_1^N, \mathbf{r}_2^N, \mathbf{r}_3^N, \dots\)</span> for the
enormous set of possible microstates within the canonical ensemble
that we are sampling. For the canonical ensemble, this state space
is equal to <span class="math notranslate nohighlight">\(V^N\)</span>, the accessible phase space.</p></li>
<li><p>The probability of sampling state <span class="math notranslate nohighlight">\(i+1\)</span> in the sequence of states
sampled depends only on state <span class="math notranslate nohighlight">\(i\)</span>, and not on previous states in the
chain.</p></li>
</ul>
<p>Since the likelihood of sampling a new state is only related to what
current state we are in, we can define a transition probability,
<span class="math notranslate nohighlight">\(\Pi(m\rightarrow n)\)</span>, which defines the likelihood of transitioning
from state <span class="math notranslate nohighlight">\(m\)</span> to state <span class="math notranslate nohighlight">\(n\)</span>. We can then imagine an algorithm in which
we start in some state <span class="math notranslate nohighlight">\(m\)</span> then transition to a new state <span class="math notranslate nohighlight">\(n\)</span> with a
probability given by <span class="math notranslate nohighlight">\(\Pi(m\rightarrow n)\)</span> and repeat this for a large
number of trials. If we do this an infinite number of times, then the
state <span class="math notranslate nohighlight">\(m\)</span> will appear with an overall probability given by <span class="math notranslate nohighlight">\(p(m)\)</span>, where
<span class="math notranslate nohighlight">\(p(m)\)</span> is the <em>limiting</em> probability distribution that does not depend
on any of the other states (unlike the transition probability). When
sampling from the canonical ensemble, then, we want <span class="math notranslate nohighlight">\(p(m)\)</span> to equal
<span class="math notranslate nohighlight">\(p(\mathbf{r}_m^N)_{NVT}\)</span> - that is, the likelihood of sampling state
<span class="math notranslate nohighlight">\(m\)</span> if we take enough states from our Markov chain is equal to the
probability of sampling that state according to the canonical ensemble
distribution function. Thus, we need to find an expression for the
transition probability, <span class="math notranslate nohighlight">\(\Pi\)</span>, that yields this correct limiting
distribution.</p>
<p><img alt="image" src="../_images/fig_10_2.png" />{width=”100%”}</p>
</section>
<section id="detailed-balance-and-the-metropolis-algorithm">
<h2>Detailed balance and the Metropolis algorithm<a class="headerlink" href="#detailed-balance-and-the-metropolis-algorithm" title="Permalink to this headline">#</a></h2>
<p>At equilibrium, the probability of finding the system in a configuration
<span class="math notranslate nohighlight">\(\mathbf{r}_m^N\)</span> must be stationary, meaning that the probability
distribution of the canonical ensemble is invariant with time (this is a
consequence of ergodicity) and is equal to the limiting distribution of
our Markov chain. If we think about a Markov chain as a very large
sequence of states, then for the probability of a particular state to be
stationary, the number of transitions into that state must be the same
as the number of transitions out of it. Think of this like a mass
balance in transport - the flux into a particular state is equal to the
flux out of it, otherwise we would “accumulate” probability for that
state. Therefore, it must be the case that in any given Markov chain the
number of trials that generate new states from a particular state must
be equal to the total number of trials from all other states that
generate the original configuration. If we write the probability of
transitioning from some configuration <span class="math notranslate nohighlight">\(\mathbf{r}_m^N\)</span> to
<span class="math notranslate nohighlight">\(\mathbf{r}_n^N\)</span> as <span class="math notranslate nohighlight">\(\Pi(\mathbf{r}_m^N \rightarrow \mathbf{r}_n^N)\)</span> and
the probability of being in state <span class="math notranslate nohighlight">\(\mathbf{r}_m^N\)</span> as
<span class="math notranslate nohighlight">\(p(\mathbf{r}_m^N)\)</span>, then we can fulfill the condition that
<span class="math notranslate nohighlight">\(p(\mathbf{r}_m^N)\)</span> is stationary by imposing the condition of
<strong>detailed balance</strong>:</p>
<div class="math notranslate nohighlight">
\[\label{app_a_detailed_balance}
p(\mathbf{r}_m^N) \Pi(\mathbf{r}_m^N \rightarrow \mathbf{r}_n^N) = p(\mathbf{r}_n^N) \Pi(\mathbf{r}_n^N \rightarrow \mathbf{r}_m^N)\]</div>
<p>This condition states that the probability of being in a particular
state <span class="math notranslate nohighlight">\(m\)</span> and transitioning to a new one <span class="math notranslate nohighlight">\(n\)</span> is the same as the
probability of being in the new state <span class="math notranslate nohighlight">\(n\)</span> and transitioning to the old
one <span class="math notranslate nohighlight">\(m\)</span>. We can rearrange this expression to write:</p>
<div class="math notranslate nohighlight">
\[\frac{p(\mathbf{r}_m^N)}{p(\mathbf{r}_n^N)}  = \frac{ \Pi(\mathbf{r}_n^N \rightarrow \mathbf{r}_m^N)}{\Pi(\mathbf{r}_m^N \rightarrow \mathbf{r}_n^N)}\]</div>
<p>Writing detailed balance in this form more clearly shows the consequence
of this definition - if the probability of state <span class="math notranslate nohighlight">\(m\)</span>,
<span class="math notranslate nohighlight">\(p(\mathbf{r}_m^N)\)</span>, is 10 times larger than the probability of state
<span class="math notranslate nohighlight">\(n\)</span>, then this expression says that there will be 10 times more
transitions from state <span class="math notranslate nohighlight">\(n\)</span> to <span class="math notranslate nohighlight">\(m\)</span> than transitions from <span class="math notranslate nohighlight">\(m\)</span> to <span class="math notranslate nohighlight">\(n\)</span>,
agreeing with expectations. Enforcing this condition for all possible
pairs of states guarantees that the number of transitions into and out
of each state is equal if an infinite number of transitions are
attempted (detailed balance is actually an overly stringent criterion -
we could achieve the same properties while enforcing a less stringent
relationship between transition probabilities, but that is outside the
scope of this class).</p>
<p>If a system obeys detailed balance, then the Markov chain must reach a
stationary probability distribution which is necessarily true for any
equilibrium system. Having defined the principle of detailed balance, we
can now apply this to a particular Markov chain that samples states
within the canonical ensemble by following the <strong>Metropolis</strong> algorithm.
The key aspect of the Metropolis algorithm is to further divide the
transition probability,
<span class="math notranslate nohighlight">\(\Pi(\mathbf{r}_m^N \rightarrow \mathbf{r}_n^N)\)</span>, into two terms - the
probability of generating a new trial state,
<span class="math notranslate nohighlight">\(g(\mathbf{r}_m^N \rightarrow \mathbf{r}_n^N)\)</span>, and the probability of
accepting the new trial state,
<span class="math notranslate nohighlight">\(\alpha (\mathbf{r}_m^N \rightarrow \mathbf{r}_n^N)\)</span>:</p>
<div class="math notranslate nohighlight">
\[\Pi(\mathbf{r}_m^N \rightarrow \mathbf{r}_n^N) = g(\mathbf{r}_m^N \rightarrow \mathbf{r}_n^N) \alpha(\mathbf{r}_m^N \rightarrow \mathbf{r}_n^N)\]</div>
<p>The equation for detailed balance can then be rewritten as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
%p(\mathbf{r}_m^N) g(\mathbf{r}_m^N \rightarrow \mathbf{r}_n^N) \alpha(\mathbf{r}_m^N \rightarrow \mathbf{r}_n^N) &amp;= p(\mathbf{r}_n^N) g(\mathbf{r}_n^N \rightarrow \mathbf{r}_m^N) \alpha(\mathbf{r}_n^N \rightarrow \mathbf{r}_m^N ) \notag \\ 
\frac{g(\mathbf{r}_m^N \rightarrow \mathbf{r}_n^N) \alpha(\mathbf{r}_m^N \rightarrow \mathbf{r}_n^N)}{g(\mathbf{r}_n^N \rightarrow \mathbf{r}_m^N) \alpha(\mathbf{r}_n^N \rightarrow \mathbf{r}_m^N )} &amp;= \frac{p(\mathbf{r}_n^N)}{p(\mathbf{r}_m^N)}
\end{aligned}\end{split}\]</div>
<p>Now, we can connect this expression explicitly to the canonical
ensemble. In the canonical ensemble, the probability of finding a
particular state <span class="math notranslate nohighlight">\(m\)</span> is related to that state’s Boltzmann weight, so we
can write:</p>
<div class="math notranslate nohighlight">
\[p(\mathbf{r}_m^N)_{NVT} = \frac{\exp \left [ -\beta E(\mathbf{r}_m^N) \right ]}{Z}\]</div>
<p>Next, we assume that the probability <span class="math notranslate nohighlight">\(g\)</span> for generating trial moves is
symmetric, and then write that
<span class="math notranslate nohighlight">\(g(\mathbf{r}_m^N \rightarrow \mathbf{r}_n^N) = g(\mathbf{r}_n^N \rightarrow \mathbf{r}_m^N)\)</span>.
We can assume this because in general we can <strong>arbitrarily</strong> choose a
function for <span class="math notranslate nohighlight">\(g\)</span> as long as the detailed balance condition is satisfied.
Combining these expressions, we then write:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\frac{g(\mathbf{r}_m^N \rightarrow \mathbf{r}_n^N) \alpha(\mathbf{r}_m^N \rightarrow \mathbf{r}_n^N)}{g(\mathbf{r}_n^N \rightarrow \mathbf{r}_m^N) \alpha(\mathbf{r}_n^N \rightarrow \mathbf{r}_m^N )} &amp;= \frac{p(\mathbf{r}_n^N)_{NVT}}{p(\mathbf{r}_m^N)_{NVT}} \\
\frac{\alpha(\mathbf{r}_m^N \rightarrow \mathbf{r}_n^N)}{\alpha(\mathbf{r}_n^N \rightarrow \mathbf{r}_m^N)} &amp;= \exp \left \{ -\beta \left [ E(\mathbf{r}_n^N) - E(\mathbf{r}_m^N) \right ] \right \} \label{app_a_acceptance_condition}
\end{aligned}\end{split}\]</div>
<p>Eq.
<span class="xref myst">[app_a_acceptance_condition]</span>{reference-type=”eqref”
reference=”app_a_acceptance_condition”} stipulates the conditions on the
acceptance condition,
<span class="math notranslate nohighlight">\(\alpha(\mathbf{r}_m^N \rightarrow \mathbf{r}_n^N)\)</span>, that leads to
correct Boltzmann-weighted sampling of configurations in the canonical
ensemble. Importantly, the partition function drops out of this
expression, resolving the issue of being unable to calculate the
partition function explicitly. In principle, several choices of the
acceptance condition could fulfill the conditions imposed detailed
balance; the choice used in the original derivation of the Metropolis
algorithm is:</p>
<div class="math notranslate nohighlight">
\[\label{app_a_acceptance}
\alpha(\mathbf{r}_m^N \rightarrow \mathbf{r}_n^N) = \text{min} \left ( 1, \exp \left \{ -\beta \left [ E(\mathbf{r}_n^N) - E(\mathbf{r}_m^N) \right ] \right \} \right )\]</div>
<p>This condition fulfills eq.
<span class="xref myst">[app_a_acceptance_condition]</span>{reference-type=”eqref”
reference=”app_a_acceptance_condition”}. This is apparent if we consider
the case where <span class="math notranslate nohighlight">\(p(\mathbf{r}_n^N) &lt; p(\mathbf{r}_m^N)\)</span>, then:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(E(\mathbf{r}_n^N) - E(\mathbf{r}_m^N) &gt; 0\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\exp \left \{ -\beta \left [ E(\mathbf{r}_n^N) - E(\mathbf{r}_m^N) \right ] \right \} &lt; 1\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\alpha(\mathbf{r}_m^N \rightarrow \mathbf{r}_n^N) = \exp \left \{ -\beta \left [ E(\mathbf{r}_n^N) - E(\mathbf{r}_m^N) \right ] \right \}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\alpha(\mathbf{r}_n^N \rightarrow \mathbf{r}_m^N) = 1\)</span></p></li>
</ul>
<p>The last two quantities satisfy the ratio stipulated in eq.
<span class="xref myst">[app_a_acceptance_condition]</span>{reference-type=”ref”
reference=”app_a_acceptance_condition”}. Finally, it is very important
to note that it is possible for the system to stay in the same state;
that is:</p>
<div class="math notranslate nohighlight">
\[\Pi(\mathbf{r}_m \rightarrow \mathbf{r}_m) = 1 - \sum_{n\ne m} \Pi(\mathbf{r}_m \rightarrow \mathbf{r}_n)\]</div>
<p>Any given Markov chain generated using the Metropolis Monte Carlo
algorithm can thus have many consecutive identical states, particularly
if the system reaches a local energy minimum.</p>
<p>Based on this derivation, the Metropolis Monte Carlo algorithm for
correctly sampling states from the canonical ensemble consists of the
following steps (given in Problem Set 2):</p>
<ol class="arabic simple">
<li><p>Assume the system is in a configuration, <span class="math notranslate nohighlight">\(\mathbf{r}_m^N\)</span>, which is
state <span class="math notranslate nohighlight">\(i\)</span> in a Markov chain.</p></li>
<li><p>Generate a trial configuration <span class="math notranslate nohighlight">\(\mathbf{r}_n^N\)</span> according to the
probability <span class="math notranslate nohighlight">\(g(\mathbf{r}_m^N \rightarrow \mathbf{r}^N_n)\)</span>. There
can be many possible ways of generating trial configurations (or
many “moves”), as noted below.</p></li>
<li><p>Calculate the energy difference between the new and old
configurations and calculate the probability of transitioning to the
new state, <span class="math notranslate nohighlight">\(\alpha(\mathbf{r}_m^N \rightarrow \mathbf{r}_n^N)\)</span>
according to Eq.
<span class="xref myst">[app_a_acceptance]</span>{reference-type=”ref”
reference=”app_a_acceptance”}.</p></li>
<li><p>Generate a uniform random number in the range [0, 1]. If the
random number is less than the transition probability, then state
<span class="math notranslate nohighlight">\(i +1\)</span> in the Markov chain has the new configuration
<span class="math notranslate nohighlight">\(\mathbf{r}_n^N\)</span> and the system configuration is updated; that is,
the new trial move is <em>accepted</em>. If the random number is greater
than the transition probability, then state <span class="math notranslate nohighlight">\(i+1\)</span> in the Markov
chain has the old configuration (<span class="math notranslate nohighlight">\(\mathbf{r}_m^N\)</span>), the system
configuration remain the same, and the move is rejected. This step
is the stochastic implementation of Eq.
<span class="xref myst">[app_a_acceptance]</span>{reference-type=”ref”
reference=”app_a_acceptance”}. Note that according to Eq.
<span class="xref myst">[app_a_acceptance]</span>{reference-type=”ref”
reference=”app_a_acceptance”}, all transitions in which the system
energy is lowered are automatically accepted.</p></li>
<li><p>Repeat steps 2-4 until a sufficient number of states in the Markov
chain are generated.</p></li>
<li><p>Approximate the ensemble-average value of some observable
<span class="math notranslate nohighlight">\(Y(\mathbf{r}^N)\)</span> by averaging over all states in the Markov chain.
Note that many states will be repeated, and we include consecutive
identical states (which appear when moves are rejected). Averaging
over all states in the Markov chain then calculates
<span class="math notranslate nohighlight">\(\langle Y(\mathbf{r}^N)\rangle_{NVT}\)</span>.</p></li>
</ol>
<p>Metropolis Monte Carlo has several advantages. First, the acceptance
ratio only relies on the energies of the two states, and as a result the
rule for generating trials moves with a probability given by <span class="math notranslate nohighlight">\(g\)</span> can be
arbitrary and does not have to be physically meaningful. For example,
typical trial moves in a system consisting of a series of liquid-like
particles could be the slight displacement of a single particle, the
rotation of an entire molecule, the displacement of several particles
simultaneously, or non-physical moves such as “hopping” a particle from
one side of the system to the other. This feature also means that
many-body potentials can be easily used to calculate system energies,
which is more difficult to do in molecular dynamics simulations that
require pair potentials. In addition, because all configurations are
sampled according to their equilibrium probability distributions,
averaging observables over simulation configurations generates ensemble
averages. The downside, however, is that the algorithm is only useful
for calculating equilibrium thermodynamic properties and not observing
system kinetics.</p>
<p>Some care has to be taken in computing ensemble-average quantities. One
choice that can affect values is the starting configuration. If an
initial configuration is generated that is a high energy (and thus
unlikely) state, then it may contribute to a large degree to a resulting
ensemble average even if its actual Boltzmann weight is low. In other
words, imagine a chain with only 10 states; the initial state will
contribute to 1/10 of the ensemble-average even if it should actually
contribute to a much smaller degree. As a result, it is typical to run a
MC algorithm for an initial period of steps that are treated as an
“equilibration” period so that any unphysical, high energy starting
configuration relaxes to a set of low-energy configurations. Inspection
of the MC equations indeed shows that there should generally be a
decrease in the system energy until a set of configurations with similar
low-energy values are obtained.</p>
<p>We finish by summarizing the Metropolis Monte Carlo approach as follows.
The goal is to calculate the ensemble-average value of some quantity
that depends on the configuration of the system, <span class="math notranslate nohighlight">\(Y(\mathbf{r}^N)\)</span>,
which could be a parameter like the energy, pressure, temperature, etc.
To do so explicitly, we could sum over all possible microstates in the
canonical ensemble, weighted by the appropriate Boltzmann factor, to
calculate this ensemble average. However, this sum is impossible to
calculate. Instead, we calculate an approximation for the ensemble
average stochastically by sampling states from the canonical ensemble
with the correct probability. Since the partition function, and thus
probability, are not generally known, we instead set up a Markov chain
of states, where the likelihood of sampling a new state depends only on
the current state. By invoking the principle of detailed balance, we
determine the value of the transition probability between any two
arbitrary states. The Metropolis algorithm then boils down to attempting
to sample a particular state, calculating the probability with which
that state should be sampled, and either accepting or rejecting the new
state. This process is repeated until the estimate of the given quantity
converges.</p>
</section>
<section id="molecular-dynamics-the-idea">
<h2>Molecular dynamics: the idea<a class="headerlink" href="#molecular-dynamics-the-idea" title="Permalink to this headline">#</a></h2>
<p>We have now introduced Metropolis Monte Carlo as a rigorous method for
sampling configurations from the canonical ensemble by generating a
Markov chain of states with a correct probability. However, Metropolis
Monte Carlo still suffers from drawbacks; one problem is to ensure that
states are efficiently sampled (i.e. avoiding repeatedly testing states
where particles overlap, for example). Another fundamental problem is
invoking a concept of time - as Metropolis MC cannot be applied to
calculate time-dependent properties of a system, it cannot be used to
calculate non-equilibrium behavior (also because it assumes that we are
sampling from an equilibrium ensemble) or system properties that depend
on particle velocities. For example, one cannot calculate a diffusion
coefficient, which is an equilibrium property of a system, from a MC
simulation. There are some variations on the Metropolis algorithm that
seek to improve on this deficiency, but they are outside of the scope of
the present discussion.</p>
<p>In Molecular Dynamics, we avoid these two issues by introducing an
approach which tries to closely resemble experimental procedures.
Specifically, we assume that each particle in the system obeys Newton’s
laws of motion, and then apply these equations of motion repeatedly to
generate system configurations. It is (generally) assumed that quantum
effects do not contribute and hence we refer to this as a classical
simulation method. Specifically, we discretize a time interval into
distinct steps, and at each step we calculate forces acting on each
particle to determine the next configuration. There is no stochastic
element to a basic molecular dynamics simulation, although in practice
the limitations of computer precision mean that there will always be
some minimal randomness introduced into a simulation. Since we are
calculating forces that attempt to reproduce the features of a physical
system, each configuration of the system generated during a MD
simulation is physically obtainable (in principle) and we do not have to
worry about particles overlapping. Moreover, we can explicitly calculate
a timescale associated with behavior, and can also model non-equilibrium
events. There are still issues with the technique - notably, the problem
of ensuring that we simulate systems for sufficiently long enough times
to observe the behavior we are interested in - but the problems are
distinct from those of MC simulations.</p>
<p>We will start by defining a basic MD algorithm, in analogy to the basic
MC algorithm:</p>
<ol class="arabic simple">
<li><p>Choose a starting configuration, <span class="math notranslate nohighlight">\(\mathbf{r}^N(t)\)</span> where <span class="math notranslate nohighlight">\(t=0\)</span>.</p></li>
<li><p>Generate initial particle velocities, <span class="math notranslate nohighlight">\(\textbf{v}^N(t)\)</span> where <span class="math notranslate nohighlight">\(t=0\)</span>.</p></li>
<li><p>Compute the forces acting on all particles, <span class="math notranslate nohighlight">\(\textbf{f}^N(t)\)</span>, at
time <span class="math notranslate nohighlight">\(t\)</span>.</p></li>
<li><p>Update <span class="math notranslate nohighlight">\(\textbf{v}^N(t)\)</span> and <span class="math notranslate nohighlight">\(\textbf{r}^N(t)\)</span> using
<span class="math notranslate nohighlight">\(\textbf{f}^N(t)\)</span> and advance the time to <span class="math notranslate nohighlight">\(t+\Delta t\)</span>, where
<span class="math notranslate nohighlight">\(\Delta t\)</span> is the simulation timestep.</p></li>
<li><p>Repeat steps 3-4 until a sufficient number of timesteps have
elapsed. Periodically compute and save the value of some observables
(e.g., temperature, pressure).</p></li>
<li><p>Approximate the ensemble average value of some observable
<span class="math notranslate nohighlight">\(Y(\mathbf{r}^N)\)</span> by averaging over states sampled during a period
of time during which the system is at equilibrium.</p></li>
</ol>
<p>Conceptually, the algorithm is fairly straightforward; we will now
explore details of its implementation. We will skip the step about
generating initial velocities and come back to that discussion in the
next lecture; first, we will discuss the core two steps of the MD
algorithm.</p>
</section>
<section id="calculating-forces">
<h2>Calculating forces<a class="headerlink" href="#calculating-forces" title="Permalink to this headline">#</a></h2>
<p>The most time-consuming, and perhaps most important, aspect of the MD
algorithm is the force calculation. First, recall that we generally have
defined interactions in terms of energies, which was used directly in
the Metropolis Monte Carlo algorithm. We can write the force on each
particle as:</p>
<div class="math notranslate nohighlight">
\[\begin{aligned}
\textbf{f}_i &amp;= -\left ( \frac{\partial E(\textbf{r}^N)}{\partial x_i}\right ) \hat{\textbf{x}} -\left ( \frac{\partial E(\textbf{r}^N)}{\partial y_i}\right ) \hat{\textbf{y}} -\left ( \frac{\partial E(\textbf{r}^N)}{\partial z_i}\right ) \hat{\textbf{z}}
\end{aligned}\]</div>
<p>Here, <span class="math notranslate nohighlight">\(\textbf{f}_i\)</span> is the force acting on particle <span class="math notranslate nohighlight">\(i\)</span>,
<span class="math notranslate nohighlight">\(E(\textbf{r}^N)\)</span> is the potential energy of the entire system,
<span class="math notranslate nohighlight">\(x_i, y_i, z_i\)</span> are the <span class="math notranslate nohighlight">\(x/y/z\)</span> positions of particle <span class="math notranslate nohighlight">\(i\)</span> (i.e. the
three components of the vector <span class="math notranslate nohighlight">\(\textbf{r}_i\)</span>), and
<span class="math notranslate nohighlight">\(\hat{\textbf{x}}, \hat{\textbf{y}}, \hat{\textbf{z}}\)</span> are unit vectors
in each of the Cartesian directions. The force on each particle is thus
the gradient of the potential energy function, and in general is a
function of all other particle positions which are calculated by summing
pairwise potentials. For example, let’s consider the calculation of the
forces on a single particle in a system of <span class="math notranslate nohighlight">\(N\)</span>-particles that only
interact via pairwise Lennard-Jones potentials. We can then calculate
the force on particle <span class="math notranslate nohighlight">\(i\)</span> (which only depends on the interactions of <span class="math notranslate nohighlight">\(i\)</span>
with other particles, and not on the interactions of other particles
with each other) as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\textbf{f}_i &amp;= -\left ( \frac{\partial E(\textbf{r}^N)}{\partial x_i}\right ) \hat{\textbf{x}} -\left ( \frac{\partial E(\textbf{r}^N)}{\partial y_i}\right ) \hat{\textbf{y}} -\left ( \frac{\partial E(\textbf{r}^N)}{\partial z_i}\right ) \hat{\textbf{z}} \\
&amp;= -\sum_{j\ne i}^N  \left ( \frac{\partial E_{LJ}(r_{ij})}{\partial x_i}\right ) \hat{\textbf{x}} + \left ( \frac{\partial E_{LJ}(r_{ij})}{\partial y_i}\right ) \hat{\textbf{y}} + \left ( \frac{\partial E_{LJ}(r_{ij})}{\partial z_i}\right ) \hat{\textbf{z}}
\end{aligned}\end{split}\]</div>
<p>Here, <span class="math notranslate nohighlight">\(r_{ij} = \sqrt{\textbf{r}_{ij} \cdot \textbf{r}_{ij}}\)</span> is the
scalar distance between particle <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span>, where <span class="math notranslate nohighlight">\(\textbf{r}_{ij}\)</span> is
the vector distance and we compute the scalar distance from the dot
product. Note that calculating the distance is a time-consuming step
since the square root function is computationally expensive. We can also
define components of the distance as <span class="math notranslate nohighlight">\(x_j-x_i \equiv x_{ij}\)</span> etc. for
the other axes. Recalling the form of the Lennard-Jones potential, we
can write an expression for the force (arbitrarily in the x-direction)
as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
- \left ( \frac{\partial E_{LJ}(r_{ij})}{\partial x_i}\right ) &amp;= -  \left ( \frac{\partial r_{ij}}{\partial x_i}\right )\left ( \frac{\partial E_{LJ}(r_{ij})}{\partial  r_{ij}}\right ) \\
&amp;= -\left ( \frac{\partial [(x_j - x_i)^2 + (y_j - y_i)^2 + (z_j - z_i)^2]^{1/2}}{\partial x_i}\right ) \left ( \frac{\partial E_{LJ}( r_{ij})}{\partial  r_{ij}}\right )  \\
&amp;= -\left (\frac{-(x_j-x_i)}{[(x_j - x_i)^2 + (y_j - y_i)^2 + (z_j - z_i)^2]^{1/2}}\right )\left ( \frac{\partial E_{LJ}( r_{ij})}{ r_{ij}}\right )  \\
&amp;= \left (\frac{ x_{ij}}{ r_{ij}} \right )\left ( \frac{\partial E_{LJ}( r_{ij})}{\partial  r_{ij}}\right ) \\
&amp;= \left (\frac{ x_{ij}}{r_{ij}} \right ) \frac{\partial }{\partial r_{ij}} \left (4\epsilon_{ij} \left [ \left (\frac{\sigma_{ij}}{ r_{ij}}\right )^{12} - \left (\frac{\sigma_{ij}}{ r_{ij}}\right )^6\right ] \right) \\
&amp;= \left (\frac{ x_{ij}}{ r_{ij}} \right) \left (\frac{-48 \epsilon_{ij}}{ r_{ij}} \left [ \left (\frac{\sigma_{ij}}{ r_{ij}}\right )^{12} - \frac{1}{2}\left (\frac{\sigma_{ij}}{ r_{ij}}\right )^6\right ] \right ) \\
&amp;=-\frac{48 \epsilon_{ij}  x_{ij}}{ r_{ij}^2} \left [ \left (\frac{\sigma_{ij}}{ r_{ij}}\right )^{12} - \frac{1}{2}\left (\frac{\sigma_{ij}}{ r_{ij}}\right )^6\right ] \\
\therefore \textbf{f}_i  &amp;= -\sum_{j\ne i} \frac{48 \epsilon_{ij}}{ r_{ij}^2} \left [ \left (\frac{\sigma_{ij}}{ r_{ij}}\right )^{12} - \frac{1}{2}\left (\frac{\sigma_{ij}}{ r_{ij}}\right )^6\right ] \left [  x_{ij} \hat{\textbf{x}} +  y_{ij} \hat{\textbf{y}} +  z_{ij} \hat{\textbf{z}}\right ]
\end{aligned}\end{split}\]</div>
<p>Substituting in this expression to the equation above gives us a term
that is very similar to the LJ potential (and hence can be calculated
with minimal additional computational expense). The chosen sign
convention is because of how we define the distance in the x-direction;
in Eq. 11.20, if <span class="math notranslate nohighlight">\(x_{ij} &gt; 0\)</span>, indicating that the x-position of
particle <span class="math notranslate nohighlight">\(j\)</span> is more positive than the x-position of particle <span class="math notranslate nohighlight">\(i\)</span>, then
the magnitude of the force will be <em>positive</em> for
<span class="math notranslate nohighlight">\(r_{ij} &gt; 2^{1/6} \sigma\)</span> and the sign of the force will correctly point
in the +x-direction, indicating that particle <span class="math notranslate nohighlight">\(i\)</span> will experience a
force to move toward particle <span class="math notranslate nohighlight">\(j\)</span>. This agrees with the expectations of
an attractive potential.</p>
<p>Finally, recall that because we obey Newton’s laws of motion, we can
calculate the forces of the entire system by summing over pairs of
particles, calculating the force on one particle due to the other one,
and using Newton’s 3rd law to immediately obtain the force on the other
particle in the pair by reversing the sign of the force calculated. This
approach also reduces the number of necessary calculations. Having
defined the force calculations, in the next lecture we will continue
with algorithms to update positions.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./lecture_files"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="Lecture10.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Monte Carlo Simulations</p>
      </div>
    </a>
    <a class="right-next"
       href="Lecture12.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">MD Thermostats</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#recommended-textbooks">Recommended textbooks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#topics-in-this-lecture">Topics in this lecture</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#announcements">Announcements</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#importance-sampling-and-markov-chains">Importance sampling and Markov chains</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#detailed-balance-and-the-metropolis-algorithm">Detailed balance and the Metropolis algorithm</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#molecular-dynamics-the-idea">Molecular dynamics: the idea</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#calculating-forces">Calculating forces</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Reid van Lehn, Matt Gebbie, Rose Cersonsky
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>