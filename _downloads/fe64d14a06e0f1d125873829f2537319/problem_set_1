<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>problem_set_1_2019</title>
  <style>
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<p><strong>Question 1: Polymer dimensions</strong></p>
<p>Ideal polymer chains are often described as undergoing <em>random
walks</em> on a lattice. Like ideal gases, the monomers in an ideal
polymer chain do not interact with each other; that is, the segments of
the chain do not exclude volume and can overlap. Consider a
<strong>one-dimensional</strong> ideal polymer chain composed of <span
class="math inline"><em>N</em></span> independent segments. One end of
the chain is placed at the origin. A single chain conformation can then
be generated by iteratively placing a single segment of the chain a
distance <span class="math inline"><em>b</em></span> in either the
positive or negative <span class="math inline"><em>x</em></span>
dimension from the current chain end - <em>i.e.</em>, the chain
elongates by taking “steps” along the one-dimensional coordinate. The
end-to-end distance of the chain, <span
class="math inline"><em>x</em></span>, is the distance between the
origin and the end of the last segment placed. Figure 1 shows an example
for <span class="math inline"><em>N</em> = 8</span> in which the
end-to-end distance is <span class="math inline"> − 2<em>b</em></span>
after all 8 steps are taken.</p>
<figure>
<img src="pset_1_random_walk_fig.png" />
<figcaption>Example 1D polymer configuration, with <span
class="math inline"><em>N</em> = 8</span> and <span
class="math inline"><em>x</em> =  − 2<em>b</em></span>.</figcaption>
</figure>
<p><strong>(a)</strong> For a one-dimensional ideal chain with <span
class="math inline"><em>N</em></span> segments and segment size <span
class="math inline"><em>b</em></span>, calculate the probability, <span
class="math inline"><em>p</em>(<em>x</em>)</span>, that the end-to-end
distance of the polymer is equal to <span
class="math inline"><em>x</em></span>. Assume that there is an
<strong>equal likelihood</strong> of taking a step in either the
positive or negative direction for each chain segment.</p>
<p>From the problem statement, the final position of the chain end,
<span class="math inline"><em>x</em></span>, depends on the number of
steps taken in each direction. We can write the number of steps in the
positive direction as <span class="math inline"><em>n</em></span>, so
that the number of steps in the negative direction is <span
class="math inline"><em>N</em> − <em>n</em></span>. The probability of
obtaining a particular value of <span
class="math inline"><em>n</em></span> is then equal to the number of
possible ways that <span class="math inline"><em>n</em></span> steps can
be taken out of <span class="math inline"><em>N</em></span> total steps,
divided by the total number of possible ways of taking steps. The number
ways of taking <span class="math inline"><em>n</em></span>
indistinguishable steps out of <span
class="math inline"><em>N</em></span> total steps is given by:</p>
<p><span class="math display">$$\Omega(n) =
\frac{N!}{n!(N-n!)}$$</span></p>
<p>The total number of ways of taking steps is <span
class="math inline">2<sup><em>N</em></sup></span>, since for each of the
<span class="math inline"><em>N</em></span> steps there are two possible
choices. Therefore, the probability of taking <span
class="math inline"><em>n</em></span> steps in the positive direction
is:</p>
<p><span class="math display">$$p(n)=
\frac{1}{2^N}\frac{N!}{n!(N-n)!}$$</span></p>
<p>Substituting <span
class="math inline"><em>n</em> = (<em>N</em>+<em>x</em>/<em>b</em>)/2</span>
we obtain a probability distribution for <span
class="math inline"><em>x</em></span> instead of <span
class="math inline"><em>n</em></span>:</p>
<p><span class="math display">$$p(x) =
\frac{1}{2^N}\frac{N!}{[(N+x/b)/2]![(N-x/b)/2]!}$$</span></p>
<p><strong>(b)</strong> For the chain described in part
<strong>a</strong>, show that in the large <span
class="math inline"><em>N</em></span> limit the probability distribution
<span class="math inline"><em>p</em>(<em>x</em>)</span> can be
approximated by:</p>
<p><span class="math display">$$p(x) = \frac{1}{\sqrt{2\pi Nb^2}}  \exp
\left ( -\frac{x^2}{2Nb^2}\right )$$</span></p>
<p>Hint: define the quantity <span
class="math inline"><em>x</em>/<em>N</em><em>b</em> ≡ <em>a</em></span>,
where <span class="math inline"><em>a</em> ≪ 1</span> in the large <span
class="math inline"><em>N</em></span> limit, and write a series
expansion for <span class="math inline">ln (1−<em>a</em>)</span> when
appropriate.</p>
<p>In the large <span class="math inline"><em>N</em></span> limit, we
can simplify the result from part <strong>a</strong> by taking the
logarithm of <span class="math inline"><em>p</em>(<em>x</em>)</span> and
using Stirling’s relation:</p>
<p><span class="math display">$$\begin{aligned}
\ln p(x)  &amp;= -N\ln 2 + N \ln N - (N + x/b)/2 \ln (N + x/b)/2 - (N-
x/b)/2 \ln(N-x/b)/2 \\
&amp;=  N \ln N - (N + x/b)/2 \ln (N + x/b) - (N- x/b)/2 \ln(N-x/b) \\
&amp;= N \ln N - N(1 + x/Nb)/2 \ln N (1+x/Nb) - N(1-x/Nb)/2 \ln
N(1-x/Nb)
\end{aligned}$$</span></p>
<p>To simplify these expressions a bit we’ll define <span
class="math inline"><em>x</em>/<em>N</em><em>b</em> ≡ <em>a</em></span>
and collect terms:</p>
<p><span class="math display">$$\begin{aligned}
\ln p(x)  &amp;= \frac{N}{2} \left [2 \ln N - (1+a) \ln N - (1+a) \ln
(1+a) - (1-a) \ln N - (1-a) \ln (1-a) \right ] \\
&amp;= -\frac{N}{2} \left [(1+a) \ln (1+a) + (1-a) \ln (1-a) \right ]
\end{aligned}$$</span></p>
<p>Next, we can use the Taylor expansion <span class="math inline">$\ln
(1-a) = -a - \frac{1}{2}a^2 \dots$</span> to simplify this expression.
Since <span class="math inline"><em>a</em> ≪ 1</span>, we will truncate
the expansion at second order:</p>
<p><span class="math display">$$\begin{aligned}
\ln p(x)  &amp;= -\frac{N}{2} \left [(1+a) \left ( a - \frac{1}{2} a^2
\right ) + (1-a) \left ( -a - \frac{1}{2} a^2 \right ) \right ] \\
&amp;=   -\frac{N}{2} \left [ a - \frac{1}{2} a^2 + a^2 - \frac{1}{2}
a^3 - a -\frac{1}{2} a^2 + a^2 + \frac{1}{2} a^3 \right ] \\
&amp;= -\frac{Na^2}{2} \\  
&amp;= -\frac{x^2}{2Nb^2}\\
\therefore p(x)  &amp;= C\exp \left ( -\frac{x^2}{2Nb^2}\right )
\end{aligned}$$</span></p>
<p>We leave the constant <span class="math inline"><em>C</em></span> to
recognize that the probability distribution is not properly normalized,
since Stirling’s approximation is inexact. To normalize this
probability, we can use the relation that <span
class="math inline">∫<sub>−∞</sub><sup>∞</sup><em>p</em>(<em>x</em>)<em>d</em><em>x</em> = 1</span>
and evaluate the Gaussian integral:</p>
<p><span class="math display">$$\begin{aligned}
\int_{-\infty}^{\infty} C\exp \left ( -\frac{x^2}{2Nb^2}\right )dx
&amp;= 1 \\
C \sqrt{2\pi Nb^2} &amp;= 1 \\
C &amp;= \frac{1}{\sqrt{2\pi Nb^2}} \\
\therefore  p(x)  &amp;= \frac{1}{\sqrt{2\pi Nb^2}}  \exp \left (
-\frac{x^2}{2Nb^2}\right )
\end{aligned}$$</span></p>
<p><strong>(c)</strong> Show that the entropy of an ideal
one-dimensional chain in the large <span
class="math inline"><em>N</em></span> limit is given by:</p>
<p><span class="math display">$$S(N, x) = -\frac{k_Bx^2}{2Nb^2} +
S(N)$$</span></p>
<p>where <span class="math inline"><em>S</em>(<em>N</em>)</span> is a
constant that is not dependent on <span
class="math inline"><em>x</em></span>.</p>
<p>As noted in part <strong>a</strong>, the probability of obtaining a
final position <span class="math inline"><em>x</em></span> can be
written as: <span class="math display">$$p(x)  = \frac{\Omega(N,
x)}{\Omega(N)}$$</span></p>
<p>We can thus use this relation and our expression for <span
class="math inline"><em>p</em>(<em>x</em>)</span> in the large <span
class="math inline"><em>N</em></span> limit to find the entropy:</p>
<p><span class="math display">$$\begin{aligned}
S(N, x) &amp;= k_B \ln \Omega(N, x) \\
&amp;= k_B \ln \left [ p(x) \Omega(N)\right ] \\
&amp;= k_B \ln \left [   \frac{1}{\sqrt{2\pi Nb^2}}  \exp \left (
-\frac{x^2}{2Nb^2}\right ) \Omega(N) \right ]\\
&amp;= k_B \ln  \left [ \exp \left ( -\frac{x^2}{2Nb^2}\right )  \right
] + k_B  \ln  \left [ \frac{1}{\sqrt{2\pi Nb^2}}  \Omega(N)  \right ] \\
&amp;= -\frac{k_B x^2}{2Nb^2} + S(N)
\end{aligned}$$</span></p>
<p>In the last line we collect the terms that are not a function of
<span class="math inline"><em>x</em></span>.</p>
<p><strong>Question 2: Magnetization of a paramagnet</strong></p>
<p>Consider a system of <span class="math inline"><em>N</em></span>
distinguishable, non-interacting atoms with magnetic dipole moments
(spins) in a magnetic field <span class="math inline"><em>H</em></span>
at constant temperature. Each spin <span
class="math inline"><em>s</em><sub><em>i</em></sub></span> has a
magnetic moment <span class="math inline"><em>μ</em></span> and can be
in one of two states: parallel to the field (<span
class="math inline"><em>s</em><sub><em>i</em></sub> = 1</span>) or
anti-parallel to the field (<span
class="math inline"><em>s</em><sub><em>i</em></sub> =  − 1</span>). The
energy of each microstate is due only to interactions between the spins
and the magnetic field, and is given by:</p>
<p><span class="math display">$$E = -\sum_{i=1}^N s_i \mu H$$</span></p>
<p>The magnetization of the material is defined as:</p>
<p><span class="math display">$$\begin{aligned}
M = \sum_i^N s_i \mu = -\frac{E}{H}
\end{aligned}$$</span></p>
<p>This model is commonly used to describe paramagnetic materials. In
this problem, we will derive an expression for the ensemble-average
magnetization of a paramagnet in a magnetic field.</p>
<p><strong>(a)</strong> Assuming that the paramagnet has a fixed energy
<span class="math inline"><em>E</em></span>, write an expression for the
entropy as a function of the number of spins aligned with the field,
<span class="math inline"><em>N</em><sub>+</sub></span>, and the total
number of spins, <span class="math inline"><em>N</em></span>.</p>
<p>We can first define <span
class="math inline"><em>N</em><sub>+</sub></span> as the number of spins
for which <span
class="math inline"><em>s</em><sub><em>i</em></sub> = 1</span>, <span
class="math inline"><em>N</em><sub>−</sub></span> is the number fo which
<span class="math inline"><em>s</em><sub><em>i</em></sub> =  − 1</span>,
and <span
class="math inline"><em>N</em><sub>+</sub> + <em>N</em><sub>−</sub> = <em>N</em></span>.
Using these definitions we can then write for the energy:</p>
<p><span class="math display">$$\begin{aligned}
    E &amp;= -\mu H \sum_i^N s_i\\
    &amp;= -\mu H  [N_+ (1) + N_-(-1) ]\\
    &amp;= -\mu H (2N_+ - N)
    
\end{aligned}$$</span></p>
<p>We can write the degeneracy of this particular energy level as:</p>
<p><span class="math display">$$\Omega(E) =
\frac{N!}{N_+!(N-N_+)!}$$</span></p>
<p>Note that this expression assumes that spins are distinguishable but
the order within each group of spins does not matter, which is a
reasonable treatment of spins on a lattice since each lattice position
is uniquely distinguishable but spins cannot interchange positions.
Using the Boltzmann expression for the entropy:</p>
<p><span class="math display">$$\begin{aligned}
    S &amp;= k_B \ln \Omega(E) \\
    &amp;= k_B \ln \left [ \frac{N!}{N_+!(N-N_+)!} \right ] \\
    &amp;= k_B \left [ N \ln N - N_+ \ln N_+ - (N-N_+)\ln(N-N_+) \right
]
    
\end{aligned}$$</span></p>
<p><strong>(b)</strong> Derive an expression for <span
class="math inline"><em>N</em><sub>+</sub></span> as a function of the
number of spins <span class="math inline"><em>N</em></span>, the
magnetic field strength <span class="math inline"><em>H</em></span>, the
magnetic moment <span class="math inline"><em>μ</em></span>, and the
temperature <span class="math inline"><em>T</em></span> (or as a
function of <span
class="math inline"><em>β</em> ≡ 1/<em>k</em><sub><em>B</em></sub><em>T</em></span>).</p>
<p>To obtain a temperature dependence, we can relate the entropy to the
energy via the relation <span class="math inline">$\left (
\frac{\partial S}{\partial E} \right )_{N, V} = 1/T$</span> to identify
an expression for <span
class="math inline"><em>N</em><sub>+</sub></span>:</p>
<p><span class="math display">$$\begin{aligned}
    \frac{1}{T} &amp;= \left ( \frac{\partial S}{\partial E} \right
)_{N, V} \\
    &amp;=  \left ( \frac{\partial S}{\partial E} \right )_{N, V} \\
    &amp;= \left ( \frac{\partial S}{\partial N_+} \right )_{N, V} \left
( \frac{\partial N_+}{\partial E} \right )_{N, V}
    
\end{aligned}$$</span></p>
<p>We can obtain these derivatives from prior expressions:</p>
<p><span class="math display">$$\begin{aligned}
    E &amp;= -\mu H (2N_+ - N) \\
    \therefore \left ( \frac{\partial N_+}{\partial E} \right )_{N, V}
&amp;= -\frac{1}{2H\mu}\\
    S &amp;=  k_B \left [ N \ln N - N_+ \ln N_+ - (N-N_+)\ln(N-N_+)
\right ] \\
    \therefore \left ( \frac{\partial S}{\partial N_+} \right )_{N, V}
&amp;= - k_B \ln \left ( \frac{N_+}{N-N_+} \right )
    
\end{aligned}$$</span></p>
<p>Combining these expressions with the expression for the temperature
gives:</p>
<p><span class="math display">$$\begin{aligned}
    \frac{1}{T} &amp;=k_B \ln \left ( \frac{N_+}{N-N_+} \right )
\frac{1}{2 H \mu} \\
    2\beta H\mu &amp;= \ln \left ( \frac{N_+}{N-N_+} \right ) \\
    -\ln \left ( \frac{1}{\frac{N}{N_+} - 1} \right ) &amp;= -2\beta H
\mu \\
    \ln \left ( \frac{N}{N_+} - 1 \right ) &amp;= -2\beta H \mu \\
    \frac{N}{N_+} &amp;= 1 + \exp(-2\beta H \mu) \\
    N_+ &amp;= \frac{N}{1+\exp(-2\beta H \mu)}
    
\end{aligned}$$</span></p>
<p><strong>(c)</strong> Show that the magnetization of a paramagnet is
given by:</p>
<p><span class="math display">$$\begin{aligned}
M = N\mu \tanh (\beta \mu H)
\end{aligned}$$</span></p>
<p>We can write for the magnetization using the definition in the
problem statement:</p>
<p><span class="math display">$$\begin{aligned}
    M &amp;= -\frac{E}{H}\\
    &amp;= \mu(2N_+ - N)
    
\end{aligned}$$</span></p>
<p>We can now substitute in our expression for <span
class="math inline"><em>N</em><sub>+</sub></span> from the previous
part:</p>
<p><span class="math display">$$\begin{aligned}
    M &amp;= \mu \left ( \frac{2N}{1+\exp(-2\beta H \mu)} - N \right )
\\
    &amp;= \mu \left ( \frac{2N}{1+\exp(-2\beta H \mu)} -
\frac{N[1+\exp(-2\beta H \mu)]}{1+\exp(-2\beta H \mu)} \right ) \\
    &amp;= \mu \left ( \frac{N - N \exp(-2\beta H \mu)}{1+\exp(-2\beta H
\mu)} \right ) \\
    &amp;= N \mu \left ( \frac{1 - \exp(-2\beta H \mu)}{1+\exp(-2\beta H
\mu)} \right )\\
    &amp;= N\mu \left ( \frac{\exp(\beta H \mu) - \exp(-\beta H
\mu)}{\exp(\beta H \mu)+\exp(-\beta H \mu)} \right ) \\
    &amp;= N\mu \tanh (\beta \mu H)
    
\end{aligned}$$</span></p>
<p>This agrees with the result in the problem statement. Hence, we have
shown that we derive an expression for the magnetization of a paramagnet
using the equations of the microcanonical ensemble.</p>
<p><strong>Question 3: Mixing entropy</strong></p>
<p>Consider two different ideal fluids containing <span
class="math inline"><em>N</em><sub>1</sub></span> and <span
class="math inline"><em>N</em><sub>2</sub></span> molecules,
respectively, for a total of <span class="math inline"><em>N</em></span>
molecules. All molecules exclude the same molar volume and are assumed
to interact weakly with each other and with themselves, such that the
potential energy of the system is negligible. The two fluids are
initially completely demixed due to an impermeable partition; the
partition is then removed and the fluids are allowed to mix at constant
volume as illustrated in Figure 2. Assume also that the molecules of
each fluid are <strong>indistinguishable</strong> from the molecules of
the same fluid.</p>
<figure>
<img src="pset_1_mixing_entropy_fig.png" />
<figcaption>Diagram illustrating mixing of two initially demixed
fluids.</figcaption>
</figure>
<p><strong>(a)</strong> Assume that the two fluids occupy a fictitious
lattice that spans the available volume. Each molecule occupies a single
lattice site and all lattice sites are occupied; thus, there are are
<span class="math inline"><em>N</em><sub>1</sub></span> lattice sites
occupied by molecule 1 and <span
class="math inline"><em>N</em><sub>2</sub></span> lattice sites occupied
by molecule 2. Using this approximation, calculate <span
class="math inline"><em>Ω</em>(<em>N</em><sub>1</sub>,<em>N</em><sub>2</sub>)</span>,
which is defined as the number of microstates for the mixture of
fluids.</p>
<p>Using this approximation, we recognize that there are a total of
<span
class="math inline"><em>N</em> = <em>N</em><sub>1</sub> + <em>N</em><sub>2</sub></span>
sites on our fictitious lattice, identical arrangements of the fluids
are indistinguishable (although the fluids themselves are
distinguishable from each other), and thus the degeneracy is:</p>
<p><span class="math display">$$\Omega(N_1, N_2) =
\frac{N!}{N_1!N_2!}$$</span></p>
<p><strong>(b)</strong> Derive an expression for the entropy change
associated with mixing the two ideal fluids in terms of the mole
fractions, <span
class="math inline"><em>x</em><sub>1</sub> = <em>N</em><sub>1</sub>/<em>N</em></span>
and <span
class="math inline"><em>x</em><sub>2</sub> = <em>N</em><sub>2</sub>/<em>N</em></span>,
of the two components. That is, determine an expression for:</p>
<p><span
class="math display"><em>Δ</em><em>S</em><sub>mix</sub> = <em>S</em><sub>mixed</sub> − <em>S</em><sub>demixed</sub></span></p>
<p>We can calculate the entropy of the mixed state immediately by
invoking Stirling’s approximation for the factorials above and using the
Boltzmann expression for the entropy:</p>
<p><span class="math display">$$\begin{aligned}
S_{\textrm{mixed}} &amp;= k_B \ln \Omega(N_1, N_2)  \\
&amp;= k_B \left ( \ln N! - \ln N_1! - \ln N_2! \right ) \\
&amp;= k_B \left ( N \ln N - N - N_1 \ln N_1 + N_1 - N_2 \ln N_2 + N_2
\right ) \\
&amp;= k_B \left ( (N_1 + N_2) \ln N - N_1 \ln N_1 - N_2 \ln N_2 \right
)  \\
&amp;= -k_B \left ( N_1 \ln N_1/N + N_2 \ln N_2/N \right ) \\
&amp;= -k_B N \left ( x_1 \ln x_1 + x_2 \ln x_2 \right )
\end{aligned}$$</span></p>
<p>The entropy change associated with mixing is defined as <span
class="math inline"><em>Δ</em><em>S</em><sub>mix</sub> = <em>S</em><sub>mixed</sub> − <em>S</em><sub>demixed</sub></span>.
However, in the initial configuration of the system, with both fluids
completely separate, all configurations of each fluid are
indistinguishable since the molecules in each of the fluids separately
are indistinguishable. There is only a single unique configuration in
the initial state and hence the entropy of the initial state is
approximately 0. The entropy of mixing is thus:</p>
<p><span class="math display">$$\begin{aligned}
\Delta S_{\textrm{mix}} &amp;= S_{\textrm{mix}} \\
&amp;= -k_B N \left ( x_1 \ln x_1 + x_2 \ln x_2 \right )
\end{aligned}$$</span></p>
<p><strong>(c)</strong> Is the lattice model assumption reasonable for
molecules occupying a continuous set of positions (rather than discrete
points)? Why or why not?</p>
<p><span> The lattice model assumption transforms a <em>continuous</em>
set of particle positions to a <em>discrete</em> set in order to
estimate the degeneracy. This approximation is reasonable because we are
effectively assuming that each molecule has some set of configurations
accessible within each lattice point (i.e. within the space associated
with a lattice), but this set of configurations is identical for every
molecule and therefore will be the same in both the demixed and mixed
state, such that taking the difference between these states (in part
<strong>b</strong>) removes this large internal set of configurations
from the expression for the degeneracy. </span></p>
<p><strong>Question 4: Stirling’s approximation</strong></p>
<p>Write a Python program that calculates the percent error of
Stirling’s approximation as a function of <span
class="math inline"><em>N</em></span>, where Stirling’s approximation is
defined as:</p>
<p><span
class="math display">ln <em>N</em>! ≈ <em>N</em>ln <em>N</em> − <em>N</em></span></p>
<p>Include with your solution a copy of your Python code (including
comments as necessary), a plot of <span
class="math inline">ln <em>N</em>!</span> and Stirling’s approximation
as a function of <span class="math inline"><em>N</em></span> up to <span
class="math inline"><em>N</em> = 100</span>, and a plot of the error of
Stirling’s approximation as a function of <span
class="math inline"><em>N</em></span> up to <span
class="math inline"><em>N</em> = 100</span>. Your grade for this problem
will be based in part on the readability of your code and plots in
addition to the accuracy of the solution.</p>
<p><strong>Note: this problem is intended to provide you with practice
in Python programming prior to the assignment of the simulation
project.</strong></p>
<p>The two requested plots are provided below. Corresponding code is
available on the Canvas website.</p>
<figure>
<img src="pset_1_plot_stirling.png" style="width:55.0%" />
<figcaption>Comparison of Stirling’s approximation vs. <span
class="math inline">ln <em>N</em>!</span> as a function of <span
class="math inline"><em>N</em></span>.</figcaption>
</figure>
<figure>
<img src="pset_1_plot_stirling_error.png" style="width:55.0%" />
<figcaption>Relative error of Stirling’s approximation vs. <span
class="math inline"><em>N</em></span>, which approaches zero as <span
class="math inline"><em>N</em></span> exceeds <span
class="math inline"> ≈ 50</span>.</figcaption>
</figure>
</body>
</html>
